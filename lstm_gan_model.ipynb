{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded with shape: torch.Size([1579, 1, 2948])\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and Data Loading\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from ast import literal_eval\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Load and preprocess data\n",
    "data = pd.read_csv('adfa_ld_processed.csv')\n",
    "data['sequence'] = data['sequence'].apply(literal_eval)\n",
    "\n",
    "# Find max length and pad sequences\n",
    "max_len = max(len(seq) for seq in data['sequence'])\n",
    "def pad_sequence(seq):\n",
    "    return np.pad([int(x) for x in seq], \n",
    "                 (0, max_len - len(seq)), \n",
    "                 'constant')\n",
    "\n",
    "X = np.array([pad_sequence(seq) for seq in data['sequence']])\n",
    "y = pd.get_dummies(data['label']).values\n",
    "\n",
    "# Normalize to [0,1]\n",
    "X = (X - X.min()) / (X.max() - X.min())\n",
    "\n",
    "# Convert to tensors\n",
    "X_tensor = torch.FloatTensor(X).unsqueeze(1)\n",
    "y_tensor = torch.FloatTensor(y)\n",
    "\n",
    "# Create DataLoader\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "print(f\"Data loaded with shape: {X_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models initialized on: cpu\n",
      "Models initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: LSTM-GAN Architecture\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTMGenerator(nn.Module):\n",
    "    def __init__(self, latent_dim, sequence_length, num_classes=2, hidden_dim=512):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=latent_dim + 32,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=3,\n",
    "            batch_first=True,\n",
    "            dropout=0.3\n",
    "        )\n",
    "        \n",
    "        self.attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_dim,\n",
    "            num_heads=8,\n",
    "            dropout=0.1\n",
    "        )\n",
    "        \n",
    "        self.label_embedding = nn.Embedding(num_classes, 32)\n",
    "        \n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, sequence_length),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, z, labels, seq_len=100):\n",
    "        batch_size = z.size(0)\n",
    "        label_embed = self.label_embedding(labels)\n",
    "        z_sequence = z.unsqueeze(1).repeat(1, seq_len, 1)\n",
    "        label_sequence = label_embed.unsqueeze(1).repeat(1, seq_len, 1)\n",
    "        lstm_input = torch.cat([z_sequence, label_sequence], dim=-1)\n",
    "        \n",
    "        lstm_out, _ = self.lstm(lstm_input)\n",
    "        attn_out, _ = self.attention(lstm_out, lstm_out, lstm_out)\n",
    "        \n",
    "        return self.output_layer(attn_out.mean(dim=1))\n",
    "\n",
    "# Cell 3: Complete Architecture and Setup\n",
    "class LSTMDiscriminator(nn.Module):\n",
    "    def __init__(self, sequence_length, num_classes=2, hidden_dim=512):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=sequence_length + 32,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=3,\n",
    "            batch_first=True,\n",
    "            dropout=0.3\n",
    "        )\n",
    "        self.batch_norm = nn.BatchNorm1d(hidden_dim)\n",
    "\n",
    "        \n",
    "        self.attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_dim,\n",
    "            num_heads=8,\n",
    "            dropout=0.1\n",
    "        )\n",
    "        \n",
    "        self.label_embedding = nn.Embedding(num_classes, 32)\n",
    "        \n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, labels):\n",
    "        label_embed = self.label_embedding(labels)\n",
    "        label_sequence = label_embed.unsqueeze(1).repeat(1, x.size(1), 1)\n",
    "        lstm_input = torch.cat([x, label_sequence], dim=-1)\n",
    "        \n",
    "        lstm_out, _ = self.lstm(lstm_input)\n",
    "        attn_out, _ = self.attention(lstm_out, lstm_out, lstm_out)\n",
    "        \n",
    "        return self.output_layer(attn_out.mean(dim=1))\n",
    "\n",
    "# Configuration\n",
    "config = {\n",
    "    'n_epochs': 200,\n",
    "    'batch_size': 64,\n",
    "    'lr_g': 0.0002,\n",
    "    'lr_d': 0.0005,\n",
    "    'beta1': 0.5,\n",
    "    'beta2': 0.999,\n",
    "    'latent_dim': 128,\n",
    "    'sequence_length': X_tensor.shape[2],\n",
    "    'num_classes': y_tensor.shape[1],\n",
    "    'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "    'gp_lambda': 5.0,\n",
    "    'n_critic': 2\n",
    "}\n",
    "\n",
    "# Initialize models\n",
    "generator = LSTMGenerator(\n",
    "    config['latent_dim'], \n",
    "    config['sequence_length']\n",
    ").to(config['device'])\n",
    "\n",
    "discriminator = LSTMDiscriminator(\n",
    "    config['sequence_length']\n",
    ").to(config['device'])\n",
    "\n",
    "# Setup optimizers\n",
    "g_optimizer = Adam(generator.parameters(), lr=config['lr_g'], betas=(config['beta1'], config['beta2']))\n",
    "d_optimizer = Adam(discriminator.parameters(), lr=config['lr_d'], betas=(config['beta1'], config['beta2']))\n",
    "\n",
    "\n",
    "\n",
    "# Add schedulers\n",
    "g_scheduler = torch.optim.lr_scheduler.ExponentialLR(g_optimizer, gamma=0.995)\n",
    "d_scheduler = torch.optim.lr_scheduler.ExponentialLR(d_optimizer, gamma=0.995)\n",
    "\n",
    "# Loss function\n",
    "adversarial_loss = nn.BCELoss()\n",
    "\n",
    "print(f\"Models initialized on: {config['device']}\")\n",
    "\n",
    "print(\"Models initialized successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Penalty\n",
    "def compute_gradient_penalty(discriminator, real_samples, fake_samples, labels):\n",
    "    alpha = torch.rand(real_samples.size(0), 1, 1).to(config['device'])\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
    "    d_interpolates = discriminator(interpolates, labels)\n",
    "    gradients = torch.autograd.grad(\n",
    "        outputs=d_interpolates,\n",
    "        inputs=interpolates,\n",
    "        grad_outputs=torch.ones_like(d_interpolates),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty\n",
    "\n",
    "# Label smoothing\n",
    "def smooth_labels(size):\n",
    "    return torch.ones(size).uniform_(0.8, 1.0).to(config['device'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50403a7e7cbf4eb9953c12d04682c011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/200:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [1/200] D_loss: 0.4116 G_loss: 9.0978\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6ed9bbfedee4bd583d7c939b2d37e91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/200:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [2/200] D_loss: 0.3360 G_loss: 10.7018\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba7eae7977984c2685e4bf8f87086102",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/200:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 125\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m d_losses, g_losses\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# Start training\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m d_losses, g_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_lstm_gan\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m# Plot results\u001b[39;00m\n\u001b[1;32m    128\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m5\u001b[39m))\n",
      "Cell \u001b[0;32mIn[20], line 64\u001b[0m, in \u001b[0;36mtrain_lstm_gan\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Fake data\u001b[39;00m\n\u001b[1;32m     63\u001b[0m z \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(batch_size, config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatent_dim\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mto(config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 64\u001b[0m fake_data \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m     65\u001b[0m fake_validity \u001b[38;5;241m=\u001b[39m discriminator(fake_data, labels\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     66\u001b[0m fake_loss \u001b[38;5;241m=\u001b[39m adversarial_loss(fake_validity, fake)\n",
      "File \u001b[0;32m~/Desktop/project/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/project/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[18], line 36\u001b[0m, in \u001b[0;36mLSTMGenerator.forward\u001b[0;34m(self, z, labels, seq_len)\u001b[0m\n\u001b[1;32m     33\u001b[0m label_sequence \u001b[38;5;241m=\u001b[39m label_embed\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m1\u001b[39m, seq_len, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     34\u001b[0m lstm_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([z_sequence, label_sequence], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 36\u001b[0m lstm_out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlstm_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m attn_out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention(lstm_out, lstm_out, lstm_out)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_layer(attn_out\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/Desktop/project/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/project/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Desktop/project/.venv/lib/python3.9/site-packages/torch/nn/modules/rnn.py:1123\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1120\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1123\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1124\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1126\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1128\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1129\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1130\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1132\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1134\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1135\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   1137\u001b[0m         batch_sizes,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1144\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional,\n\u001b[1;32m   1145\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Cell 4: Fixed Training Loop Implementation\n",
    "# Cell 4: Fixed Training Loop Implementation\n",
    "import os\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Training Loop\n",
    "def train_lstm_gan():\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    save_dir = f'lstm_gan_checkpoints_{timestamp}'\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    d_losses, g_losses = [], []\n",
    "    \n",
    "    try:\n",
    "        for epoch in range(config['n_epochs']):\n",
    "            d_epoch_loss, g_epoch_loss = 0, 0\n",
    "            pbar = tqdm(dataloader, desc=f'Epoch {epoch+1}/{config[\"n_epochs\"]}')\n",
    "            \n",
    "            # Calculate noise factor for instance noise\n",
    "            noise_factor = max(0.1 * (1.0 - epoch/config['n_epochs']), 0)\n",
    "            \n",
    "            for batch_idx, (real_data, labels) in enumerate(pbar):\n",
    "                try:\n",
    "                    batch_size = real_data.size(0)\n",
    "                    \n",
    "                    # Reshape and add instance noise\n",
    "                    real_data = real_data.view(batch_size, -1, config['sequence_length']).to(config['device'])\n",
    "                    real_data += noise_factor * torch.randn_like(real_data)\n",
    "                    labels = labels.to(config['device'])\n",
    "                    \n",
    "                    # Smooth labels\n",
    "                    valid = smooth_labels((batch_size, 1))\n",
    "                    fake = torch.zeros(batch_size, 1).to(config['device'])\n",
    "                    \n",
    "                    # Train Generator\n",
    "                    if batch_idx % config['n_critic'] == 0:\n",
    "                        g_optimizer.zero_grad()\n",
    "                        z = torch.randn(batch_size, config['latent_dim']).to(config['device'])\n",
    "                        generated_data = generator(z, labels.argmax(1))\n",
    "                        generated_data = generated_data.unsqueeze(1)\n",
    "                        \n",
    "                        validity = discriminator(generated_data, labels.argmax(1))\n",
    "                        g_loss = adversarial_loss(validity, valid)\n",
    "                        \n",
    "                        g_loss.backward()\n",
    "                        torch.nn.utils.clip_grad_norm_(generator.parameters(), max_norm=1.0)\n",
    "                        g_optimizer.step()\n",
    "                        \n",
    "                        g_epoch_loss += g_loss.item()\n",
    "                    \n",
    "                    # Train Discriminator\n",
    "                    d_optimizer.zero_grad()\n",
    "                    \n",
    "                    # Real data\n",
    "                    real_validity = discriminator(real_data, labels.argmax(1))\n",
    "                    real_loss = adversarial_loss(real_validity, valid)\n",
    "                    \n",
    "                    # Fake data\n",
    "                    z = torch.randn(batch_size, config['latent_dim']).to(config['device'])\n",
    "                    fake_data = generator(z, labels.argmax(1)).unsqueeze(1).detach()\n",
    "                    fake_validity = discriminator(fake_data, labels.argmax(1))\n",
    "                    fake_loss = adversarial_loss(fake_validity, fake)\n",
    "                    \n",
    "                    # Gradient penalty\n",
    "                    gp = compute_gradient_penalty(\n",
    "                        discriminator, real_data, fake_data, labels.argmax(1)\n",
    "                    )\n",
    "                    \n",
    "                    # Total discriminator loss\n",
    "                    d_loss = (real_loss + fake_loss) / 2 + (config['gp_lambda'] * gp / batch_size)\n",
    "                    \n",
    "                    d_loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(discriminator.parameters(), max_norm=1.0)\n",
    "                    d_optimizer.step()\n",
    "                    \n",
    "                    d_epoch_loss += d_loss.item()\n",
    "                    \n",
    "                    # Update progress bar\n",
    "                    pbar.set_postfix({\n",
    "                        'D_loss': f'{d_loss.item():.4f}',\n",
    "                        'G_loss': f'{g_loss.item():.4f}' if 'g_loss' in locals() else 'N/A'\n",
    "                    })\n",
    "                    \n",
    "                except RuntimeError as e:\n",
    "                    print(f\"Batch error: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            # Calculate average losses\n",
    "            n_batches = len(dataloader)\n",
    "            avg_d_loss = d_epoch_loss / n_batches\n",
    "            avg_g_loss = g_epoch_loss / (n_batches // config['n_critic'])\n",
    "            d_losses.append(avg_d_loss)\n",
    "            g_losses.append(avg_g_loss)\n",
    "            \n",
    "            print(f\"\\nEpoch [{epoch+1}/{config['n_epochs']}] \"\n",
    "                  f\"D_loss: {avg_d_loss:.4f} G_loss: {avg_g_loss:.4f}\")\n",
    "            \n",
    "            # Step schedulers\n",
    "            g_scheduler.step()\n",
    "            d_scheduler.step()\n",
    "\n",
    "            # Save checkpoint\n",
    "            if (epoch + 1) % 50 == 0:\n",
    "                checkpoint_path = os.path.join(save_dir, f'checkpoint_epoch_{epoch+1}.pt')\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'generator_state_dict': generator.state_dict(),\n",
    "                    'discriminator_state_dict': discriminator.state_dict(),\n",
    "                    'g_optimizer_state_dict': g_optimizer.state_dict(),\n",
    "                    'd_optimizer_state_dict': d_optimizer.state_dict(),\n",
    "                    'g_loss': avg_g_loss,\n",
    "                    'd_loss': avg_d_loss\n",
    "                }, checkpoint_path)\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Training error: {e}\")\n",
    "        \n",
    "    return d_losses, g_losses\n",
    "\n",
    "# Start training\n",
    "d_losses, g_losses = train_lstm_gan()\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(d_losses, label='Discriminator Loss')\n",
    "plt.plot(g_losses, label='Generator Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('LSTM-GAN Training Progress')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
